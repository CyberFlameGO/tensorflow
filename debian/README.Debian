README.source
=============

Principles specific to this source package
------------------------------------------

1. Use "bazel query" to dump source code and generated file
   dependencies for the build targets.

2. This source packages provides CPU-only version of TF instead
   of CUDA version.
  
   (1) CPU-only version is compilable on all architectures.
       CUDA is specific to amd64 and ppc64el, and aarch64.

   (2) CPU-only version can stay in the main section.
       Once compiled with CUDA, the source must enter contrib section.

   src:caffe and src:caffe-contrib is an example for illustration.

Debian's Build System for TF
----------------------------

The build system is python3 plus ninja which builds stuff according
to bazel dump. See debian/shogun.py for detail.


Ambiguous FFT2D license
-----------------------

 https://lists.debian.org/debian-legal/2018/08/msg00005.html
 https://github.com/tensorflow/tensorflow/issues/21724
 Well, let's assume it's a free license.

 There is only one kernel that use this file. If this license
 is really problematic, we can disable the kernel and drop
 this dependency.

 - [ ] is it really problematic?

Some Upstream Issues
--------------------

1. -fvisibility=hidden
 > https://github.com/tensorflow/tensorflow/issues/9391#issuecomment-299039225

2. File already exists in database: ***.proto
 > https://github.com/tensorflow/tensorflow/issues/8394

3. cmake: tf shared lib
 > https://github.com/tensorflow/tensorflow/pull/9124

4. statically-linked lib causes symbol collision
 > https://github.com/tensorflow/tensorflow/issues/9525

Things remain to be done
========================

C and C++ interface.

- [ ] solve the following problem
- [ ] upload to experimental.

```
lumin@Asuna:~/packages/tensorflow.pkg/tensorflow$ LD_LIBRARY_PATH=. ./tf_benchmark_model --graph=../tensorflow_inception_graph.pb --show_flops --input_layer=input --input_layer_type=float
2018-09-06 14:40:04.693215: I tensorflow/tools/benchmark/benchmark_model.cc:469] Graph: [../tensorflow_inception_graph.pb]
2018-09-06 14:40:04.693261: I tensorflow/tools/benchmark/benchmark_model.cc:470] Init ops:
2018-09-06 14:40:04.693266: I tensorflow/tools/benchmark/benchmark_model.cc:471] Input layers: [input]
2018-09-06 14:40:04.693270: I tensorflow/tools/benchmark/benchmark_model.cc:472] Input shapes: [1,224,224,3]
2018-09-06 14:40:04.693273: I tensorflow/tools/benchmark/benchmark_model.cc:473] Input types: [float]
2018-09-06 14:40:04.693276: I tensorflow/tools/benchmark/benchmark_model.cc:474] Output layers: [output:0]
2018-09-06 14:40:04.693279: I tensorflow/tools/benchmark/benchmark_model.cc:475] Target layers: []
2018-09-06 14:40:04.693285: I tensorflow/tools/benchmark/benchmark_model.cc:476] Num runs: [1000]
2018-09-06 14:40:04.693288: I tensorflow/tools/benchmark/benchmark_model.cc:477] Inter-inference delay (seconds): [-1.0]
2018-09-06 14:40:04.693294: I tensorflow/tools/benchmark/benchmark_model.cc:478] Inter-benchmark delay (seconds): [-1.0]
2018-09-06 14:40:04.693317: I tensorflow/tools/benchmark/benchmark_model.cc:480] Num threads: [-1]
2018-09-06 14:40:04.693322: I tensorflow/tools/benchmark/benchmark_model.cc:481] Benchmark name: []
2018-09-06 14:40:04.693325: I tensorflow/tools/benchmark/benchmark_model.cc:482] Output prefix: []
2018-09-06 14:40:04.693331: I tensorflow/tools/benchmark/benchmark_model.cc:483] Show sizes: [0]
2018-09-06 14:40:04.693334: I tensorflow/tools/benchmark/benchmark_model.cc:484] Warmup runs: [1]
2018-09-06 14:40:04.693339: I tensorflow/tools/benchmark/benchmark_model.cc:251] Loading TensorFlow.
2018-09-06 14:40:04.693351: I tensorflow/tools/benchmark/benchmark_model.cc:258] Got config, 0 devices
2018-09-06 14:40:04.693462: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
2018-09-06 14:40:04.758646: I tensorflow/tools/benchmark/benchmark_model.cc:496] Initialized session in 0.065293s
2018-09-06 14:40:04.758721: I tensorflow/tools/benchmark/benchmark_model.cc:327] Running benchmark for max 1 iterations, max -1 seconds without detailed stat logging, with -1s sleep between inferences
2018-09-06 14:40:04.893198: F tensorflow/core/grappler/costs/op_level_cost_estimator.cc:404] Check failed: 0 < gflops (0 vs. 0)type: "CPU"
vendor: "GenuineIntel"
model: "110"
num_cores: 4
environment {
  key: "cpu_instruction_set"
  value: "SSE, SSE2"
}
environment {
  key: "eigen"
  value: "3.3.90"
}
l1_cache_size: 32768
l2_cache_size: 262144
l3_cache_size: 6291456
memory_size: 9676668928

Aborted
```


Postponed
---------

- [ ] Compile both AVX+ version and Generic version. Automatically
      choose the working one during postinst according to the machine's
      cpu capability.
- [ ] compile documentation instead of providing the raw ones.
- [ ] build libtensorflow on top of libtensorflow_framework?
- [ ] (ppc64el) what's this????????
      tensorflow/core/lib/core/threadpool.o:(.debug_addr+0x4d28): R_PPC64_ADDR64 used with TLS symbol Eigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::GetPerThread()::per_thread_
      tensorflow/core/util/work_sharder.o:(.debug_addr+0xf30): R_PPC64_ADDR64 used with TLS symbol tensorflow::per_thread_max_parallism
- [ ] make sure libtensorflow/amd64 is linked against libmkldnn
- [ ] upload to unstable.
      Wait for protobuf 3.6.1, mkl-dnn, (and possibly grpc) to enter unstable.

Python interface.

- [ ] build _pywrap_tensorflow_internal.so on top of libtensorflow*
- [ ] do we have all the required python dependencies?
- [ ] figure out how to generate python API
- [ ] is the resulting python package correct and working?
- [ ] write autopkgtest with mini python programs.


Will Never Get Fixed
--------------------

- [ ] 32-bit architecture support, if it FTBFS.
- [ ] weak architecture support (incl. mips*, arm*, etc), if it FTBFS.
- [ ] symbols control file. C++ symbols is a nightmare.
- [ ] Javascript binding tensorflow.js if no one works on it.
- [ ] Go binding if no one works on it.
- [ ] Java binding if no one works on it.
- [ ] GPU (CUDA) support if no one works on it.
      .
      If you want the CUDA version, why not use TensorFlow official binaries?
      .
      This requires us to prepare another copy of source code and
      rename it to tensorflow-cuda. (just like what I've done for
      src:caffe and src:caffe-contrib). Apart from that, without
      cuDNN, the GPU version will be pointless and useless.
      CUDA version of tensorflow is not planned yet. At the same
      time the CUDA version could also be linked against MKL.
