README.source
=============

Principles specific to this source package
------------------------------------------

1. Use "bazel query" to dump source code and generated file
   dependencies for the build targets.

2. This source packages provides CPU-only verison of TF instead
   of CUDA version.
  
   (1) CPU-only version is compilable on all architectures.
       CUDA is specific to amd64 and ppc64el, and aarch64.

   (2) CPU-only version can stay in the main section.
       Once compiled with CUDA, the source must enter contrib section.

   src:caffe and src:caffe-contrib is an example for illustration.

Debian's Build System for TF
----------------------------

The build system is python3 plus ninja which builds stuff according
to bazel dump. See debian/ninja/README.md for detail.

* Missing Symbols

  Shogun compiles shared objects. However when you are linking
  some program against the resulting shared object you may notice
  that the compiler complains about some missing symbols. To
  fix the build problem just try to search in the code tree for
  the missing symbols with tools e.g. ripgrep, and append the
  corresponding .cc files to your compilation command.

  If you look at the bazel build files you will figure out that
  TF's code is highly modularized and it's not quite easy for
  us to decide what .cc file to include in the final shared object
  without the bazel dump. The simplest choice for us is to keep
  the result as close to bazel's result as possible. As a result,
  I'm not likely to add .cc files into the resulting shared object
  by myself.

Ambiguous FFT2D license
-----------------------

 https://lists.debian.org/debian-legal/2018/08/msg00005.html
 https://github.com/tensorflow/tensorflow/issues/21724
 Well, let's assume it's a free license.

 There is only one kernel that use this file. If this license
 is really problematic, we can disable the kernel and drop
 this dependency.

 - [ ] is it really problematic?

Things remain to be done
========================

Misc.

C and C++ interface.

- [ ] is the resulting libtensorflow.so.1.10 correct and working?
  - [ ] write autopkgtest with some mini C/C++ programs.
  - [ ] find out the way to build tests (googletest).
- [ ] must we ship a copy of Eigen3?
- [ ] install eigen headers from Eigen3 and third_party directory
- [ ] upload to experimental.

Python interface.

- [ ] build _pywrap_tensorflow_internal.so on top of libtensorflow and libtensorflow_framework
- [ ] do we have all the required python dependencies?
- [ ] figure out how to generate python API
- [ ] is the resulting python package correct and working?
- [ ] write autopkgtest with mini python programs.


Postponed
---------

- [ ] Compile both AVX+ version and Generic version. Automatically
      choose the working one during postinst according to the machine's
      cpu capability.
- [ ] compile documentation instead of providing the raw ones.
- [ ] build libtensorflow on top of libtensorflow_framework?
- [ ] (ppc64el) what's this????????
      tensorflow/core/lib/core/threadpool.o:(.debug_addr+0x4d28): R_PPC64_ADDR64 used with TLS symbol Eigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::GetPerThread()::per_thread_
      tensorflow/core/util/work_sharder.o:(.debug_addr+0xf30): R_PPC64_ADDR64 used with TLS symbol tensorflow::per_thread_max_parallism
- [ ] make sure libtensorflow/amd64 is linked against libmkldnn
- [ ] upload to unstable.
      Wait for protobuf 3.6.1, mkl-dnn, (and possibly grpc) to enter unstable.

Will Never Get Fixed
--------------------

- [ ] 32-bit architecture support, if it FTBFS.
- [ ] weak architecture support (incl. mips*, arm*, etc), if it FTBFS.
- [ ] symbols control file. C++ symbols is a nightmare.
- [ ] Javascript binding tensorflow.js if no one works on it.
- [ ] Go binding if no one works on it.
- [ ] Java binding if no one works on it.
- [ ] GPU (CUDA) support if no one works on it.
      .
      If you want the CUDA version, why not use TensorFlow official binaries?
      .
      This requires us to prepare another copy of source code and
      rename it to tensorflow-cuda. (just like what I've done for
      src:caffe and src:caffe-contrib). Apart from that, without
      cuDNN, the GPU version will be pointless and useless.
      CUDA version of tensorflow is not planned yet. At the same
      time the CUDA version could also be linked against MKL.
